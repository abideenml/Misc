{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fedb95f0",
   "metadata": {},
   "source": [
    "# CHAPTER 3: Linear Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "076735b0",
   "metadata": {},
   "source": [
    "Affine transformation of input features is characterized by a linear transformation of features via weighted sum, combined\n",
    "with a translation of bias. Models whose output prediction is determined by the affine transformation of input features are linear models, where the affine transformation is specified by the chosen weights and bias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "34831364",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c3e6ff51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features: tensor([1.2081, 0.1537]) \n",
      "label: tensor([6.1023])\n"
     ]
    }
   ],
   "source": [
    "def synthetic_data(w, b, num_examples): \n",
    "    \"\"\"Generate y = Xw + b + noise.\"\"\"\n",
    "    \"\"\" Mean:0 and Standard deviation:1\"\"\"\n",
    "    X = torch.normal(0, 1, (num_examples, len(w)))\n",
    "    y = torch.matmul(X, w) + b\n",
    "    y += torch.normal(0, 0.01, y.shape)\n",
    "    return X, y.reshape((-1, 1))\n",
    "\n",
    "true_w = torch.tensor([2, -3.4])\n",
    "true_b = 4.2\n",
    "features, labels = synthetic_data(true_w, true_b, 1000)\n",
    "print('features:', features[0],'\\nlabel:', labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f01300e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_iter(batch_size, features, labels):\n",
    "    num_examples = len(features)\n",
    "    indices = list(range(num_examples))\n",
    "    # The examples are read at random, in no particular order\n",
    "    random.shuffle(indices)\n",
    "    for i in range(0, num_examples, batch_size):\n",
    "        batch_indices = torch.tensor(\n",
    "            indices[i: min(i + batch_size, num_examples)])\n",
    "        yield features[batch_indices], labels[batch_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "361c5130",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.7475,  1.8047],\n",
      "        [-0.4459, -0.6795],\n",
      "        [-0.5048,  1.0340],\n",
      "        [-0.3866, -0.3515],\n",
      "        [ 0.7413,  0.3133],\n",
      "        [ 1.4544,  1.5210],\n",
      "        [ 0.8863, -0.6586],\n",
      "        [-0.0494, -1.1076],\n",
      "        [ 0.4625,  0.6936],\n",
      "        [ 2.5180, -0.3998]]) \n",
      " tensor([[-3.4637],\n",
      "        [ 5.5979],\n",
      "        [-0.3302],\n",
      "        [ 4.6179],\n",
      "        [ 4.6279],\n",
      "        [ 1.9334],\n",
      "        [ 8.2053],\n",
      "        [ 7.8500],\n",
      "        [ 2.7761],\n",
      "        [10.5994]])\n"
     ]
    }
   ],
   "source": [
    "batch_size = 10\n",
    "for X, y in data_iter(batch_size, features, labels):\n",
    "    print(X, '\\n', y)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5867d123",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0026],\n",
      "        [-0.0014]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "w = torch.normal(0, 0.01, size=(2,1), requires_grad=True)\n",
    "b = torch.zeros(1, requires_grad=True)\n",
    "print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "37119b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linreg(X, w, b): #@save\n",
    "    \"\"\"The linear regression model.\"\"\"\n",
    "    return torch.matmul(X, w) + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1401f2f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def squared_loss(y_hat, y): #@save\n",
    "    \"\"\"Squared loss.\"\"\"\n",
    "    return (y_hat - y.reshape(y_hat.shape)) ** 2 / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c6a95c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sgd(params, lr, batch_size): #@save\n",
    "    \"\"\"Minibatch stochastic gradient descent.\"\"\"\n",
    "    with torch.no_grad():\n",
    "        for param in params:\n",
    "            param -= lr * param.grad / batch_size\n",
    "            param.grad.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d64041e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, loss 0.026966\n",
      "epoch 2, loss 0.000091\n",
      "epoch 3, loss 0.000045\n"
     ]
    }
   ],
   "source": [
    "lr = 0.03\n",
    "num_epochs = 3\n",
    "net = linreg\n",
    "loss = squared_loss\n",
    "for epoch in range(num_epochs):\n",
    "    for X, y in data_iter(batch_size, features, labels):\n",
    "        l = loss(net(X, w, b), y) # Minibatch loss in `X` and `y`\n",
    "        # Compute gradient on `l` with respect to [`w`, `b`]\n",
    "        l.sum().backward()\n",
    "        sgd([w, b], lr, batch_size) # Update parameters using their gradient\n",
    "    with torch.no_grad():\n",
    "        train_l = loss(net(features, w, b), labels)\n",
    "        print(f'epoch {epoch + 1}, loss {float(train_l.mean()):f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "691a9829",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error in estimating w: tensor([-0.0003, -0.0004], grad_fn=<SubBackward0>)\n",
      "error in estimating b: tensor([0.0007], grad_fn=<RsubBackward1>)\n"
     ]
    }
   ],
   "source": [
    "print(f'error in estimating w: {true_w - w.reshape(true_w.shape)}')\n",
    "print(f'error in estimating b: {true_b - b}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
